---
title: "1st Visual Inductive Priors for Data-Efficient Deep Learning Workshop"
layout: splash
header:
  overlay_image: https://eccv2020.eu/wp-content/uploads/2019/10/ECCV-HEADER-Main.jpg
  caption: "Photo credit: [**ECCV 2020**](https://eccv2020.eu)"
excerpt: "ECCV 2020 <br/> 23 August 2020 (morning), Glasgow UK"
intro:
  - excerpt: 'This workshop focuses on how to pre-wire deep networks with generic visual inductive innate knowledge structures, which allows to incorporate hard won existing generic knowledge from physics such as light reflection or geometry. Visual inductive priors are data efficient: What is built-in no longer has to be learned, saving valuable training data.'
feature_row:
  - image_path: /assets/images/addtocal.png
    alt: "Add to calendar"
    title: "Workshop program"
    excerpt: "Half-day program with invited speakers and challenge presentations."
    url: "#workshop-program"
    btn_label: "Read More"
    btn_class: "btn--primary"
  - image_path: /assets/images/callforpapers.png
    alt: "placeholder image 2"
    title: "Call for papers"
    excerpt: "We invite researchers to submit their recent work on data-efficient computer vision."
    url: "call-for-papers"
    btn_label: "Read More"
    btn_class: "btn--primary"
  - image_path: /assets/images/challenge.png
    title: "VIPriors challenges"
    excerpt: "Including data-efficient **action recognition**, **classification**, **detection** and **segmentation**."
    url: "challenges"
    btn_label: "Read More"
    btn_class: "btn--primary"
organizers_row:
  - image_path: /assets/images/JanVanGemert.jpg
    alt: "dr. Jan van Gemert"
    title: "dr. Jan van Gemert"
    excerpt: "Delft University of Technology"
    url: "https://jvgemert.github.io/"
    btn_label: "Website"
    btn_class: "btn--default"
  - image_path: /assets/images/blank-photo.png
    alt: "dr. Anton van den Hengel"
    title: "dr. Anton van den Hengel"
    excerpt: "University of Adelaide"
    url: "https://cs.adelaide.edu.au/~hengel/"
    btn_label: "Website"
    btn_class: "btn--default"
  - image_path: /assets/images/AttilaLengyel.jpg
    alt: "Attila Lengyel"
    title: "Attila Lengyel"
    excerpt: "Delft University of Technology"
  - image_path: /assets/images/Robert-JanBruintjes.jpg
    alt: "Robert-Jan Bruintjes"
    title: "Robert-Jan Bruintjes"
    excerpt: "Delft University of Technology"
    url: "https://rjbruin.nl"
    btn_label: "Website"
    btn_class: "btn--default"
  - image_path: /assets/images/OsmanKayhan.png
    alt: "Osman Kayhan"
    title: "Osman Kayhan"
    excerpt: "Delft University of Technology"
  - image_path: /assets/images/MarcosBaptistaRios.jpg
    alt: "Marcos Baptista Rios"
    title: "Marcos Baptista Rios"
    excerpt: "University of Alcala"
---

{% include feature_row id="intro" type="center" %}

{% include feature_row %}

# About the workshop

Data is fueling deep learning. Data is costly to gather and expensive to annotate. Training on massive datasets has a huge energy consumption adding to our carbon footprint. This workshop aims beyond the few very large companies that can accommodate ML on this scale to the long tail of smaller companies and universities with smaller datasets and smaller hardware clusters. We focus on data efficiency through visual inductive priors.

Excellent recent research investigates data efficiency in deep networks by exploiting other data sources such as unsupervised learning, re-using existing datasets, or synthesizing artificial training data. Not much attention is given on how to overcome the data dependency by adding prior knowledge to deep nets. As a consequence, all knowledge has to be (re-)learned implicitly from data, making deep networks hard to understand black boxes. This workshop aims to remedy this gap by investigating how to flexibly pre-wire deep networks with generic visual innate knowledge structures, which allows to incorporate hard won existing knowledge from physics such as light reflection or geometry.

## Workshop program

| Time          | Event                           | Details                     |
| ------------- | ------------------------------- | --------------------------- |
| 9:00 - 9:10   | Introduction                    | Speaker: dr. Jan van Gemert |
| 9:10 - 9:55   | Keynote 1                       | Speaker: TBD                |
| 9:55 - 10:40  | Keynote 2                       | Speaker: TBD                |
| 10:40 - 11:30 | Coffee break & poster session   |                             |
| 11:30 - 12:30 | Oral presentations              | Speakers: TBD               |
| 12:30 - 13:00 | Challenge winners presentations | Speakers: TBD               |

## Call for papers

Data is fueling deep learning. Data is costly to gather and expensive to annotate. Training on massive datasets has a huge energy consumption adding to our carbon footprint. This workshop aims beyond the few very large companies that can accommodate ML on this scale to the long tail of smaller companies and universities with smaller datasets and smaller hardware clusters. We focus on data efficiency through visual inductive priors.

Please see the [call for papers page](/call-for-papers) for submission instructions and deadlines.

## VIPriors Challenges

We present the "Visual Inductive Priors for Data-Efficient Computer Vision'' challenges. We offer four challenges, where models are to be trained from scratch, and we reduce the number of training samples to a fraction of the full set.

Please see the [challenges page](/challenges) for submission instructions and deadlines.

## Invited speakers

*Speakers to be announced.*

## Organizers

{% include feature_row id="organizers_row" %}
